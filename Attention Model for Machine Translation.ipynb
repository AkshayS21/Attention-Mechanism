{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation with Attention Model\n",
    "\n",
    "\n",
    "In this notebook, we  will build a Neural Machine Translation (NMT) model to translate human readable dates (\"28th of September, 2009\") into machine readable dates (\"2009-09-28\"). We will do this with an attention model, which is used to learn sophisticated mappings from one sequence to another.\n",
    "\n",
    "Let's load all the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating human readable dates into machine readable dates\n",
    "\n",
    "The attention model can be used to translate from one language to another but that task will require large training dataset and a lot of time training on GPUs. Hence in order to explore the functionality of this model, we will instead use it to translate dates written in a variety of formats to machine readable dates.\n",
    "For example, \n",
    "- $\"the 29th of August 1958\"$ to $\"1958-08-29\"$\n",
    "\n",
    "- $\"03/30/1968\"$ to $\"1968-03-30\"$\n",
    "\n",
    "- $\"24 JUNE 1987\"$ to  $\"1987-06-24\"$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "For trainig, we will use a dataset of 10000 dates in different formats and their equivalent machine readable dates.\n",
    "\n",
    "Let's print some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 16272.14it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.09.70', '1970-09-10'),\n",
       " ('4/28/90', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('tuesday july 8 2008', '2008-07-08'),\n",
       " ('08 sep 1999', '1999-09-08'),\n",
       " ('1 jan 1981', '1981-01-01'),\n",
       " ('monday may 22 1995', '1995-05-22')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load some sample dates and their corresponding machine readable dates\n",
    "\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have loaded has,\n",
    "- `dataset`: a list of tuples of (human readable date, machine readable date)\n",
    "- `human_vocab`: a python dictionary mapping all characters used in the human readable dates to an integer-valued index \n",
    "- `machine_vocab`: a python dictionary mapping all characters used in machine readable dates to an integer-valued index.  \n",
    "- `inv_machine_vocab`: the inverse dictionary of `machine_vocab`, mapping from indices back to characters. \n",
    "\n",
    "Let's preprocess the data and map the raw text data into the index values. We will also use Tx=30 (which we assume is the maximum length of the human readable date; if we get a longer input, we would have to truncate it) and Ty=10 (since \"YYYY-MM-DD\" is 10 characters long). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have:\n",
    "- `X`: where each character in the human readable dates is replaced by an index mapped to the character via `human_vocab`. Each date is further padded to $T_x = 30$ values with a special character (< pad >). `X.shape = (m, Tx)`\n",
    "- `Y`: where each character in machine readable dates is replaced by the index it is mapped to in `machine_vocab`. `Y.shape = (m, Ty)`. \n",
    "- `Xoh`: one-hot version of `X`,\n",
    "- `Yoh`: one-hot version of `Y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: monday may 22 1995\n",
      "Target date: 1995-05-22\n",
      "\n",
      "Source after preprocessing (indices): [24 26 25 16 13 34  0 24 13 34  0  5  5  0  4 12 12  8 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  6  0  1  6  0  3  3]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 9\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural machine translation with attention\n",
    "\n",
    "Let's take a look at out Model.\n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. If we are to translate a sentence from one language to another, especially if its a long sentence or a paragraph, we don't read the whole paragraph and translate it, but we pay attention to a few words in a paragraph like negation or conjugation and then translate the paragraph in pieces. That's what attention model does.\n",
    "\n",
    "\n",
    "###  Attention mechanism\n",
    "\n",
    "Here is a figure of how the model works. The diagram on the left shows the attention model. The diagram on the right shows what one \"Attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$, which are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"images/attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"images/attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Source**: Coursera.org, Deep Learning Specialization.</center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are some properties of the model that you may notice: \n",
    "\n",
    "- The LSTM at the bottom is a Bi-directional LSTM and comes before the attention model and the one at the top a one-directional LSTM. The pre-attention LSTM goes through $T_x$ time steps while the post attantion LSTM goes though $T_y$ time steps. We use two LSTMs here because $T_x$ is not necessarily equal to $T_y$.\n",
    "\n",
    "- In the figure on the right, where we implement the one step of the attention model, for a given time step ($t$), we take as input all the Hidden states of the Bi_LSTM and the previous hiddent state ($t-1$) of the post-attention LSTM. The output gives us a weighted sum of all the hidden states. The weights here decide how each character in the sentence ( or a date in this case) influences the character at time step $t$. The model will learn this influence and will try to replicate it when we test it on a new data. \n",
    "\n",
    "\n",
    "**1) `one_step_attention()`**: At step $t$, given all the hidden states of the Bi-LSTM ($[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$) and the previous hidden state of the second LSTM ($s^{<t-1>}$), `one_step_attention()` will compute the attention weights ($[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$) and output the context vector (see Figure  1 (right) for details):\n",
    "$$context^{<t>} = \\sum_{t' = 0}^{T_x} \\alpha^{<t,t'>}a^{<t'>}$$\n",
    "\n",
    "  \n",
    "**2) `model()`**: Implements the entire model. It first runs the input through a Bi-LSTM to get back $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. Then, it calls `one_step_attention()` $T_y$ times (`for` loop). At each iteration of this loop, it gives the computed context vector $c^{<t>}$ to the second LSTM, and runs the output of the LSTM through a dense layer with softmax activation to generate a prediction $\\hat{y}^{<t>}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') \n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) to\n",
    "    #concatenate it with all hidden states \"a\" \n",
    "    s_prev = repeator(s_prev)\n",
    "   # print(s_prev.shape)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis \n",
    "    concat = concatenator([a , s_prev])\n",
    "    #print(concat.shape)\n",
    "    \n",
    "    # Use densor1 to propagate concat through a small fully-connected \n",
    "    # neural network to compute the \"intermediate energies\" variable e. \n",
    "    e = densor1(concat)\n",
    "    #print(e.shape)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural \n",
    "    # network to compute the \"energies\" variable energies. \n",
    "    energies = densor2(e)\n",
    "    #print(energies.shape)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" \n",
    "    alphas = activator(energies)\n",
    "    #print(alphas.shape)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector\n",
    "    # to be given to the next (post-attention) LSTM-cell \n",
    "    context = dotor([alphas,a])\n",
    "    #print(context.shape)\n",
    "    #print(context.shape)\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global layers that will share weights to be used in 'model()'\n",
    "\n",
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of the model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    \n",
    "    # Step 1: Define  pre-attention Bi-LSTM.. \n",
    "    a = Bidirectional( LSTM(n_a, return_sequences=True ))(X)\n",
    "    #print(a.shape)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t\n",
    "        context = one_step_attention(a , s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        #  initial_state = [hidden state, cell state] \n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s,c])\n",
    "        \n",
    "        # Step 2.C: Applying Dense layer to the hidden state output of the post-attention LSTM \n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list \n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. \n",
    "    model = Model(inputs = [X,s0,c0], outputs = outputs)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 21s - loss: 15.3400 - dense_3_loss: 2.5427 - dense_3_acc: 0.5409 - dense_3_acc_1: 0.7211 - dense_3_acc_2: 0.3395 - dense_3_acc_3: 0.0812 - dense_3_acc_4: 0.9815 - dense_3_acc_5: 0.4517 - dense_3_acc_6: 0.0938 - dense_3_acc_7: 0.9269 - dense_3_acc_8: 0.2795 - dense_3_acc_9: 0.1036\n",
      "Epoch 2/10\n",
      " - 11s - loss: 8.7964 - dense_3_loss: 2.2337 - dense_3_acc: 0.9682 - dense_3_acc_1: 0.9669 - dense_3_acc_2: 0.5621 - dense_3_acc_3: 0.1861 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9379 - dense_3_acc_6: 0.3298 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.4921 - dense_3_acc_9: 0.1740\n",
      "Epoch 3/10\n",
      " - 12s - loss: 7.0478 - dense_3_loss: 2.0872 - dense_3_acc: 0.9777 - dense_3_acc_1: 0.9767 - dense_3_acc_2: 0.7124 - dense_3_acc_3: 0.3778 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9621 - dense_3_acc_6: 0.5710 - dense_3_acc_7: 0.9999 - dense_3_acc_8: 0.5813 - dense_3_acc_9: 0.2310\n",
      "Epoch 4/10\n",
      " - 12s - loss: 5.0405 - dense_3_loss: 1.8823 - dense_3_acc: 0.9799 - dense_3_acc_1: 0.9811 - dense_3_acc_2: 0.8229 - dense_3_acc_3: 0.6986 - dense_3_acc_4: 0.9999 - dense_3_acc_5: 0.9706 - dense_3_acc_6: 0.7401 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.6960 - dense_3_acc_9: 0.3030\n",
      "Epoch 5/10\n",
      " - 12s - loss: 3.4806 - dense_3_loss: 1.3701 - dense_3_acc: 0.9848 - dense_3_acc_1: 0.9843 - dense_3_acc_2: 0.8639 - dense_3_acc_3: 0.8682 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9756 - dense_3_acc_6: 0.8385 - dense_3_acc_7: 0.9999 - dense_3_acc_8: 0.7833 - dense_3_acc_9: 0.4876\n",
      "Epoch 6/10\n",
      " - 13s - loss: 2.0329 - dense_3_loss: 0.5550 - dense_3_acc: 0.9878 - dense_3_acc_1: 0.9879 - dense_3_acc_2: 0.8822 - dense_3_acc_3: 0.9321 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9785 - dense_3_acc_6: 0.8903 - dense_3_acc_7: 0.9999 - dense_3_acc_8: 0.8314 - dense_3_acc_9: 0.8149\n",
      "Epoch 7/10\n",
      " - 12s - loss: 1.0064 - dense_3_loss: 0.1323 - dense_3_acc: 0.9931 - dense_3_acc_1: 0.9930 - dense_3_acc_2: 0.9197 - dense_3_acc_3: 0.9564 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9872 - dense_3_acc_6: 0.9344 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.9306 - dense_3_acc_9: 0.9688\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.4566 - dense_3_loss: 0.0285 - dense_3_acc: 0.9968 - dense_3_acc_1: 0.9967 - dense_3_acc_2: 0.9652 - dense_3_acc_3: 0.9900 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9923 - dense_3_acc_6: 0.9707 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.9849 - dense_3_acc_9: 0.9980\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.2043 - dense_3_loss: 0.0129 - dense_3_acc: 0.9983 - dense_3_acc_1: 0.9984 - dense_3_acc_2: 0.9898 - dense_3_acc_3: 0.9972 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9914 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.9961 - dense_3_acc_9: 0.9989\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.1084 - dense_3_loss: 0.0066 - dense_3_acc: 0.9999 - dense_3_acc_1: 0.9998 - dense_3_acc_2: 0.9980 - dense_3_acc_3: 0.9998 - dense_3_acc_4: 1.0000 - dense_3_acc_5: 0.9968 - dense_3_acc_6: 0.9951 - dense_3_acc_7: 1.0000 - dense_3_acc_8: 0.9971 - dense_3_acc_9: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd31ecfef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelb = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n",
    "#model_use = modela\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999) # decay=0.01)\n",
    "modelb.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'] )\n",
    "#modelb.summary()\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))\n",
    "modelb.fit([Xoh, s0, c0], outputs, epochs=10, batch_size=100, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "source: 5 April 09\n",
      "output: 2009-04-05\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "from numpy import newaxis\n",
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "\n",
    "\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #print(source)\n",
    "    #print(human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))#.swapaxes(0,1)\n",
    "    #print(source.shape)\n",
    "    source = source[newaxis,:,:]\n",
    "    #print(source.shape)\n",
    "    prediction = modelb.predict([source,s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the activations from the network\n",
    "\n",
    "Lets now visualize the attention values in your network. We'll propagate an example through the network, then visualize the values of $\\alpha^{\\langle t, t' \\rangle}$. \n",
    "\n",
    "To figure out where the attention values are located, let's start by printing a summary of the model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_map(model, input_vocabulary, inv_output_vocabulary, text, n_s = 64, num = 7 , Tx = 30, Ty = 10):\n",
    "    \"\"\"\n",
    "    Plot the attention map.\n",
    "  \n",
    "    \"\"\"\n",
    "    attention_map = np.zeros((10, 30))\n",
    "    Ty, Tx = attention_map.shape\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    layer = model.layers[num]\n",
    "\n",
    "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
    "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
    "\n",
    "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
    "    r = f([encoded, s0, c0])\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
    "\n",
    "    # Normalize attention map\n",
    "#     row_max = attention_map.max(axis=1)\n",
    "#     attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = model.predict([encoded, s0, c0])\n",
    "    \n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
    "        \n",
    "    predicted_text = list(predicted_text)\n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "    text_ = list(text)\n",
    "    \n",
    "    # get the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = Ty\n",
    "    \n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(18)\n",
    "    f.set_figheight(8.5)\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='gray')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0.0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    #f.show()\n",
    "    \n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the generated plot we can observe the values of the attention weights for each character of the predicted output. \n",
    "\n",
    "In the date translation application, we will observe that most of the time attention helps predict the date/month, and hasn't much impact on predicting the year ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x612 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attn_map(modelb, human_vocab, inv_machine_vocab, \"Friday Oct 19 2018\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x612 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attn_map(modelb, human_vocab, inv_machine_vocab, \"Saturday May 9 2018\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideas in this notebook are based on Andrew Ng's Deep Learning Specialization on Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
